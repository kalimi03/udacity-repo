# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
The data is related with direct marketing campaigns of a Portuguese banking institution. The marketing campaigns were based on phone calls. Often, more than one contact to the same client was required, in order to access if the product (bank term deposit) would be ('yes') or not ('no') subscribed.
The classification goal is to predict if the client will subscribe (yes/no) a term deposit (variable y).
The best performing model is an ensemble model StackEnsemble produced by the AutomML run. It has an accuracy rate of 91.60%.
## Scikit-learn Pipeline
The main steps and architecture is shown in below diagram.




The pipeline consists of a training script (train.py), a dataset downloaded from Portuguese banking institution, a Scikit-learn Logistic Regression, a HyperDrive for optimizing the hyperparameters. A compute instance is created and a Jupyter Notebook is used to run the training script.

Benefits of the parameter sampler chosen
The random parameter sampler for HyperDrive supports discrete and continuous hyperparameters, as well as early termination of low-performance runs. It is simple to use, eliminates bias and increases the accuracy of the model.

Benefits of the early stopping policy chosen
The early termination policy BanditPolicy for HyperDrive automatically terminates poorly performing runs and improves computational efficiency.
## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
The AutoML run was executed with below AutoMLConfig settings:
automl_config = AutoMLConfig(
    experiment_timeout_minutes=30,
    task='classification',
    primary_metric='accuracy',
    training_data=x,
    label_column_name='y',
    n_cross_validations=2)

The best model generated from the run was a StackEnsemble model.

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

## Future work
Apply model interpretability of AutoML on more complex and larger datasets, to gain speed and valuable insights in feature engineering, which can in turn be used to refine complex model accuracy

Experiment with different hyperparameter sampling methods like Gird sampling or Bayesian sampling on the Scikit-learn LogicRegression model or other custom-coded machine learning models.

